{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from transformers import BertTokenizer, TFBertModel, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_type='cimm-kzn/endr-bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_bert = BertTokenizer.from_pretrained(bert_type)\n",
    "model = BertModel.from_pretrained(bert_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_tokenize = \"This is text that I want to tokenize, but I also do it with span inside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "span = (18, 36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Torch for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_type)\n",
    "model = BertModel.from_pretrained(bert_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(text_to_tokenize)\n",
    "input_ids = torch.tensor(tokens).unsqueeze(0)  # Batch size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 10531, 10124, 15541, 10189,   177, 21528, 10114, 18436, 18687,\n",
       "         10870,   117, 10473,   177, 10379, 10149, 10271, 10169, 51551, 22978,\n",
       "           102]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21, 768])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize text with span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_type)\n",
    "model = BertModel.from_pretrained(bert_type)\n",
    "\n",
    "tokens = tokenizer.encode(text_to_tokenize)\n",
    "input_ids = torch.tensor(tokens).unsqueeze(0)\n",
    "outputs = model(input_ids)\n",
    "last_hidden_states = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(text_to_tokenize)\n",
    "tokenized_span = tokenizer.tokenize(text_to_tokenize[18:36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 21)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_text), len(last_hidden_states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_words_indices = [i+1 for i in range(len(tokenized_text)) if tokenized_text[i] in tokenized_span][:len(tokenized_span)]\n",
    "span_words_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] this is text that i want to tokenize, but i also do it with span inside [SEP]'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i want to tokenize'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([input_ids.tolist()[0][j] for j in span_words_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[177, 21528, 10114, 18436, 18687, 10870]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_ids = [input_ids.tolist()[0][j] for j in span_words_indices]\n",
    "span_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(span_ids).unsqueeze(0)\n",
    "outputs = model(input_ids)\n",
    "last_hidden_states = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0012, -0.0062, -0.0092, -0.0069, -0.0113, -0.0069],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states[0].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6198, -0.2913, -0.0801,  ...,  0.2206,  0.1563,  0.0305],\n",
       "        [ 0.4594, -0.7568,  0.0446,  ...,  0.5830,  0.5598, -0.2870],\n",
       "        [ 1.0232, -0.9621, -0.7415,  ...,  0.4972,  0.4687, -0.0192],\n",
       "        [ 0.4532, -0.3883, -0.1660,  ..., -0.2376,  0.2915, -0.4778],\n",
       "        [-0.0521, -0.3073, -0.3796,  ...,  0.0637,  0.3936, -0.2138],\n",
       "        [ 0.6270, -0.8474, -0.3692,  ...,  0.2373,  0.3379, -0.1057]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vecors_from_context_TORCH(text, span):\n",
    "    \"\"\" Get sent vec with TOCH model \"\"\"\n",
    "    if span in [None, ''] or span not in text:\n",
    "        span = text\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    tokenized_span = tokenizer.tokenize(span)\n",
    "    text_ids = tokenizer.encode(text)\n",
    "    # get tokens vecs\n",
    "    text_ids = torch.tensor(text_ids).unsqueeze(0)\n",
    "    outputs = model(text_ids)\n",
    "    last_hidden_states = outputs[0]\n",
    "    # define which vecs are related to span\n",
    "    span_words_indices = [\n",
    "        i+1 for i in range(len(tokenized_text)) if tokenized_text[i] in tokenized_span\n",
    "    ][:len(tokenized_span)]\n",
    "    span_vec = np.array(last_hidden_states[0][span_words_indices].tolist())\n",
    "    print(np.mean(span_vec, axis=0).shape)\n",
    "    #return span_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "get_vecors_from_context_TORCH(\n",
    "    \"severe abdominal cramps, leg cramps, diahhrea, after taking 10mg only 3 days.<SENT>Symptoms still persist 1 week later.<SENT>Don't take it.\", \"Don't take it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n",
      "(768,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-269-f17964a4da45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mspan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'term'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mget_vecors_from_context_TORCH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-242-03a5025c18a8>\u001b[0m in \u001b[0;36mget_vecors_from_context_TORCH\u001b[0;34m(text, span)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# get tokens vecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtext_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mlast_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# define which vecs are related to span\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m         )\n\u001b[1;32m    971\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         return F.layer_norm(\n\u001b[0;32m--> 170\u001b[0;31m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2093\u001b[0m                 layer_norm, (input,), input, normalized_shape, weight=weight, bias=bias, eps=eps)\n\u001b[1;32m   2094\u001b[0m     return torch.layer_norm(input, normalized_shape, weight, bias, eps,\n\u001b[0;32m-> 2095\u001b[0;31m                             torch.backends.cudnn.enabled)\n\u001b[0m\u001b[1;32m   2096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = pd.read_csv('../../data/interim/cadec/test.csv')\n",
    "for k in range(d.shape[0]):\n",
    "    text = d.iloc[k].to_dict()['sent']\n",
    "    span = d.iloc[k].to_dict()['term']\n",
    "    try:\n",
    "        get_vecors_from_context_TORCH(text, span)\n",
    "    except Exception as e:\n",
    "        \n",
    "        print('>> ', text)\n",
    "        print('>> ', span)\n",
    "        print('\\n', e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sent</th>\n",
       "      <th>text</th>\n",
       "      <th>code</th>\n",
       "      <th>STR</th>\n",
       "      <th>SNMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>muscle problems</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "      <td>Absolutely none.</td>\n",
       "      <td>Absolutely none.&lt;SENT&gt;No muscle or joint probl...</td>\n",
       "      <td>10028641</td>\n",
       "      <td>Myopathy</td>\n",
       "      <td>['Myopathy', 'Myopathy', 'Myopathy', 'Myopathy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exhaustion</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Exhaustion, malaise, upset stomach/constant hu...</td>\n",
       "      <td>Exhaustion, malaise, upset stomach/constant hu...</td>\n",
       "      <td>10015667</td>\n",
       "      <td>Exhaustion</td>\n",
       "      <td>['Exhaustion', 'Exhaustion', 'Exhaustion', 'Ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brain Fog</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>I am diabetic and my numbers weren't horrible ...</td>\n",
       "      <td>Fatigue, Brain Fog, Stuttering, Bad OCD!.&lt;SENT...</td>\n",
       "      <td>10027371</td>\n",
       "      <td>Mental dullness</td>\n",
       "      <td>['Mentally dull', 'Mental dullness', 'Mental d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cramping neck muscels</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>been off it 10 months,drs spent fortune 160 k ...</td>\n",
       "      <td>vertigo caused by cramping neck muscels,all th...</td>\n",
       "      <td>10028334</td>\n",
       "      <td>Muscle spasms</td>\n",
       "      <td>['Spasm', 'Spasm, NOS', 'Muscle spasm', 'Muscl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hips hurt</td>\n",
       "      <td>126</td>\n",
       "      <td>135</td>\n",
       "      <td>Stopped, and pains lessened in one week; took ...</td>\n",
       "      <td>took Lipitor for over a year with no negative ...</td>\n",
       "      <td>10033432</td>\n",
       "      <td>Pain in hip</td>\n",
       "      <td>['Hip pain', 'Hip pain', 'Hip pain', 'Hip pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>not being able to concentrate</td>\n",
       "      <td>634</td>\n",
       "      <td>663</td>\n",
       "      <td>The light headedness and often foggy vision, s...</td>\n",
       "      <td>Persistent triedness,loss of concentration,unc...</td>\n",
       "      <td>10010248</td>\n",
       "      <td>Concentration ability impaired</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>Lots of gas</td>\n",
       "      <td>108</td>\n",
       "      <td>119</td>\n",
       "      <td>Dosage for past 2 yrs has been 40 mg once a day.</td>\n",
       "      <td>Muscle and joint aches in arms, elbows, and ca...</td>\n",
       "      <td>10016766</td>\n",
       "      <td>Flatulence</td>\n",
       "      <td>['Flatulence', 'Flatulence', 'Flatulence', 'Fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>Body Pains</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Body Pains all over, major on going muscle cra...</td>\n",
       "      <td>Body Pains all over, major on going muscle cra...</td>\n",
       "      <td>10018074</td>\n",
       "      <td>Generalised aching</td>\n",
       "      <td>['Generalized aches and pains', 'Generalized a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>Constant sleepiness</td>\n",
       "      <td>220</td>\n",
       "      <td>239</td>\n",
       "      <td>Also, hot/cold fever-like sensations in the sk...</td>\n",
       "      <td>51 yr old female.&lt;SENT&gt;After 2 1/2 years on it...</td>\n",
       "      <td>10020765</td>\n",
       "      <td>Hypersomnia</td>\n",
       "      <td>['Hypersomnia', 'Hypersomnia, NOS', 'Hypersomn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>abnoraml dreams</td>\n",
       "      <td>1102</td>\n",
       "      <td>1117</td>\n",
       "      <td>2 months later, the pain was back.</td>\n",
       "      <td>I had been taking Lipitor 10mg for 2 years.&lt;SE...</td>\n",
       "      <td>10000125</td>\n",
       "      <td>Abnormal dreams</td>\n",
       "      <td>['Dream disorder', 'Abnormal dreams', 'Abnorma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>881 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              term  start   end  \\\n",
       "0                  muscle problems     36    44   \n",
       "1                       Exhaustion      0    10   \n",
       "2                        Brain Fog      9    18   \n",
       "3            cramping neck muscels     18    39   \n",
       "4                        hips hurt    126   135   \n",
       "..                             ...    ...   ...   \n",
       "876  not being able to concentrate    634   663   \n",
       "877                    Lots of gas    108   119   \n",
       "878                     Body Pains      0    10   \n",
       "879            Constant sleepiness    220   239   \n",
       "880                abnoraml dreams   1102  1117   \n",
       "\n",
       "                                                  sent  \\\n",
       "0                                     Absolutely none.   \n",
       "1    Exhaustion, malaise, upset stomach/constant hu...   \n",
       "2    I am diabetic and my numbers weren't horrible ...   \n",
       "3    been off it 10 months,drs spent fortune 160 k ...   \n",
       "4    Stopped, and pains lessened in one week; took ...   \n",
       "..                                                 ...   \n",
       "876  The light headedness and often foggy vision, s...   \n",
       "877   Dosage for past 2 yrs has been 40 mg once a day.   \n",
       "878  Body Pains all over, major on going muscle cra...   \n",
       "879  Also, hot/cold fever-like sensations in the sk...   \n",
       "880                 2 months later, the pain was back.   \n",
       "\n",
       "                                                  text      code  \\\n",
       "0    Absolutely none.<SENT>No muscle or joint probl...  10028641   \n",
       "1    Exhaustion, malaise, upset stomach/constant hu...  10015667   \n",
       "2    Fatigue, Brain Fog, Stuttering, Bad OCD!.<SENT...  10027371   \n",
       "3    vertigo caused by cramping neck muscels,all th...  10028334   \n",
       "4    took Lipitor for over a year with no negative ...  10033432   \n",
       "..                                                 ...       ...   \n",
       "876  Persistent triedness,loss of concentration,unc...  10010248   \n",
       "877  Muscle and joint aches in arms, elbows, and ca...  10016766   \n",
       "878  Body Pains all over, major on going muscle cra...  10018074   \n",
       "879  51 yr old female.<SENT>After 2 1/2 years on it...  10020765   \n",
       "880  I had been taking Lipitor 10mg for 2 years.<SE...  10000125   \n",
       "\n",
       "                                STR  \\\n",
       "0                          Myopathy   \n",
       "1                        Exhaustion   \n",
       "2                   Mental dullness   \n",
       "3                     Muscle spasms   \n",
       "4                       Pain in hip   \n",
       "..                              ...   \n",
       "876  Concentration ability impaired   \n",
       "877                      Flatulence   \n",
       "878              Generalised aching   \n",
       "879                     Hypersomnia   \n",
       "880                 Abnormal dreams   \n",
       "\n",
       "                                                  SNMS  \n",
       "0    ['Myopathy', 'Myopathy', 'Myopathy', 'Myopathy...  \n",
       "1    ['Exhaustion', 'Exhaustion', 'Exhaustion', 'Ex...  \n",
       "2    ['Mentally dull', 'Mental dullness', 'Mental d...  \n",
       "3    ['Spasm', 'Spasm, NOS', 'Muscle spasm', 'Muscl...  \n",
       "4    ['Hip pain', 'Hip pain', 'Hip pain', 'Hip pain...  \n",
       "..                                                 ...  \n",
       "876                                                 []  \n",
       "877  ['Flatulence', 'Flatulence', 'Flatulence', 'Fl...  \n",
       "878  ['Generalized aches and pains', 'Generalized a...  \n",
       "879  ['Hypersomnia', 'Hypersomnia, NOS', 'Hypersomn...  \n",
       "880  ['Dream disorder', 'Abnormal dreams', 'Abnorma...  \n",
       "\n",
       "[881 rows x 8 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../../data/interim/cadec/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
